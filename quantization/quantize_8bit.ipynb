{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd6bb61d-5dee-4553-85ab-d625c08aeac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ___________ ____        ____  ____  ____ \n",
      "   / ____/ ___// __ \\      / __ \\/ __ \\/ __ \\\n",
      "  / __/  \\__ \\/ /_/ /_____/ /_/ / /_/ / / / /\n",
      " / /___ ___/ / ____/_____/ ____/ ____/ /_/ / \n",
      "/_____//____/_/         /_/   /_/    \\___\\_\\ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 导入必要的包\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pickle\n",
    "import numpy as np\n",
    "from ppq.api import espdl_quantize_onnx\n",
    "from ppq.core import TargetPlatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b891bc4f-4040-4036-ab53-f609db396fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: 准备校准数据集\n",
    "class CalibrationDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.FloatTensor(X).unsqueeze(1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "# 加载校准数据\n",
    "with open('../dataset/cal.pkl', 'rb') as f:\n",
    "    X_cal, _ = pickle.load(f)\n",
    "\n",
    "cal_dataset = CalibrationDataset(X_cal)\n",
    "cal_loader = DataLoader(cal_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0026ead-0136-45bd-9be1-edd99baec69f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:37:44] PPQ Quantization Fusion Pass Running ...       Finished.\n",
      "[14:37:44] PPQ Quantize Simplify Pass Running ...         Finished.\n",
      "[14:37:44] PPQ Parameter Quantization Pass Running ...    Finished.\n",
      "[14:37:44] PPQ Runtime Calibration Pass Running ...       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1): 100%|██████████| 500/500 [00:22<00:00, 21.86it/s]\n",
      "Calibration Progress(Phase 2): 100%|██████████| 500/500 [00:34<00:00, 14.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "[14:38:41] PPQ Quantization Alignment Pass Running ...    Finished.\n",
      "[14:38:41] PPQ Passive Parameter Quantization Running ... Finished.\n",
      "--------- Network Snapshot ---------\n",
      "Num of Op:                    [27]\n",
      "Num of Quantized Op:          [27]\n",
      "Num of Variable:              [74]\n",
      "Num of Quantized Var:         [74]\n",
      "------- Quantization Snapshot ------\n",
      "Num of Quant Config:          [102]\n",
      "ACTIVATED:                    [30]\n",
      "OVERLAPPED:                   [34]\n",
      "PASSIVE:                      [38]\n",
      "Network Quantization Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysing Graphwise Quantization Error(Phrase 1):: 100%|█| 8/8 [00:00<00:00, 12.\n",
      "Analysing Graphwise Quantization Error(Phrase 2):: 100%|█| 8/8 [00:01<00:00,  6.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                              | NOISE:SIGNAL POWER RATIO \n",
      "/layers/layers.3/conv/conv.6/Conv: | ████████████████████ | 20.176%\n",
      "/classifier/classifier.2/Gemm:     | █████████████████    | 17.618%\n",
      "/layers/layers.3/conv/conv.3/Conv: | ███████████          | 11.092%\n",
      "/layers/layers.2/conv/conv.6/Conv: | █████████            | 8.726%\n",
      "/layers/layers.3/conv/conv.0/Conv: | ████████             | 8.590%\n",
      "/layers/layers.2/conv/conv.3/Conv: | █████                | 4.843%\n",
      "/layers/layers.1/conv/conv.6/Conv: | █████                | 4.603%\n",
      "/layers/layers.2/conv/conv.0/Conv: | ████                 | 3.662%\n",
      "/layers/layers.1/conv/conv.3/Conv: | ███                  | 3.166%\n",
      "/layers/layers.1/conv/conv.0/Conv: | ██                   | 2.454%\n",
      "/layers/layers.0/conv/conv.6/Conv: | ██                   | 2.438%\n",
      "/layers/layers.0/conv/conv.3/Conv: | █                    | 0.678%\n",
      "/layers/layers.0/conv/conv.0/Conv: |                      | 0.340%\n",
      "/first/first.0/Conv:               |                      | 0.079%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysing Layerwise quantization error:: 100%|██| 14/14 [00:10<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                              | NOISE:SIGNAL POWER RATIO \n",
      "/first/first.0/Conv:               | ████████████████████ | 3.588%\n",
      "/layers/layers.1/conv/conv.3/Conv: | ██                   | 0.394%\n",
      "/layers/layers.3/conv/conv.3/Conv: | ██                   | 0.292%\n",
      "/layers/layers.0/conv/conv.3/Conv: | █                    | 0.140%\n",
      "/layers/layers.2/conv/conv.0/Conv: | █                    | 0.131%\n",
      "/layers/layers.2/conv/conv.3/Conv: | █                    | 0.112%\n",
      "/layers/layers.0/conv/conv.0/Conv: |                      | 0.091%\n",
      "/layers/layers.3/conv/conv.0/Conv: |                      | 0.087%\n",
      "/layers/layers.0/conv/conv.6/Conv: |                      | 0.061%\n",
      "/layers/layers.1/conv/conv.6/Conv: |                      | 0.049%\n",
      "/layers/layers.2/conv/conv.6/Conv: |                      | 0.048%\n",
      "/layers/layers.1/conv/conv.0/Conv: |                      | 0.022%\n",
      "/classifier/classifier.2/Gemm:     |                      | 0.018%\n",
      "/layers/layers.3/conv/conv.6/Conv: |                      | 0.008%\n",
      "\u001b[38;5;2m[INFO][ESPDL][2024-12-16 14:38:54]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2024-12-16 14:38:54]:  \u001b[mskip not QuantableOperation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: 执行量化\n",
    "ONNX_MODEL_PATH = \"../training/gesture_model.onnx\"\n",
    "EXPORT_PATH = \"../deployment/model/gesture_model_int8.espdl\"\n",
    "input_shape = [1, 1, 96, 96]\n",
    "\n",
    "graph = espdl_quantize_onnx(\n",
    "    onnx_import_file=ONNX_MODEL_PATH,\n",
    "    espdl_export_file=EXPORT_PATH,\n",
    "    calib_dataloader=cal_loader,\n",
    "    calib_steps=500,\n",
    "    input_shape=[input_shape],\n",
    "    target=\"esp32s3\",\n",
    "    num_of_bits=8,\n",
    "    device=\"cpu\",\n",
    "    error_report=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8aae6aa-ff04-48f2-a2e3-7df143feb3ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "开始评估量化模型性能...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/75 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'bool' object has no attribute 'sum'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(test_dataset, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# 执行评估\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m \u001b[43mevaluate_quantized_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[4], line 25\u001b[0m, in \u001b[0;36mevaluate_quantized_model\u001b[0;34m(graph, test_loader, y_test)\u001b[0m\n\u001b[1;32m     23\u001b[0m         _, predicted \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     24\u001b[0m         total \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m         correct \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mpredicted\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\u001b[43mtotal\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msum\u001b[49m()\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 计算并打印结果\u001b[39;00m\n\u001b[1;32m     28\u001b[0m avg_time \u001b[38;5;241m=\u001b[39m (total_time \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(test_loader)) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m  \u001b[38;5;66;03m# 转换为毫秒\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'bool' object has no attribute 'sum'"
     ]
    }
   ],
   "source": [
    "# Cell 4: 评估量化后的模型\n",
    "from ppq.executor import TorchExecutor\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_quantized_model(graph, test_loader, y_test):\n",
    "    \"\"\"\n",
    "    评估量化后的模型性能\n",
    "    \"\"\"\n",
    "    executor = TorchExecutor(graph=graph, device='cpu')\n",
    "    total_time = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    print(\"\\n开始评估量化模型性能...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            start = time.time()\n",
    "            outputs = executor.forward(inputs=batch)\n",
    "            total_time += (time.time() - start)\n",
    "            \n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(outputs[0], 1)\n",
    "            total += batch.size(0)\n",
    "            correct += (predicted == y_test[total-batch.size(0):total]).sum().item()\n",
    "\n",
    "    # 计算并打印结果\n",
    "    avg_time = (total_time / len(test_loader)) * 1000  # 转换为毫秒\n",
    "    accuracy = (correct / total) * 100\n",
    "\n",
    "    print(f\"\\n评估结果:\")\n",
    "    print(f\"平均推理时间: {avg_time:.2f} ms\")\n",
    "    print(f\"模型准确率: {accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_time, accuracy\n",
    "\n",
    "# 加载测试数据\n",
    "with open('../dataset/test.pkl', 'rb') as f:\n",
    "    X_test, y_test = pickle.load(f)\n",
    "\n",
    "# 准备测试数据集\n",
    "test_dataset = CalibrationDataset(X_test)  # 复用之前的Dataset类\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 执行评估\n",
    "evaluate_quantized_model(graph, test_loader, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287a1b90-f2e3-477f-854a-e16256b29126",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../dataset/Web_Images_Processed_Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e391033-197a-44a6-985a-f92717b561ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: 使用量化后的模型识别一张图片\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    图片预处理函数\n",
    "    1. 读取图片\n",
    "    2. 转换为灰度图\n",
    "    3. 调整大小\n",
    "    4. 归一化\n",
    "    \"\"\"\n",
    "    # 读取图片\n",
    "    img = cv2.imread(image_path)\n",
    "    # 转换为灰度图\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 调整大小\n",
    "    TARGET_SIZE = (96, 96)\n",
    "    resized = cv2.resize(gray, TARGET_SIZE)\n",
    "    # 归一化\n",
    "    normalized = resized.astype('float32') / 255.0\n",
    "    # 添加 batch 和 channel 维度\n",
    "    image_tensor = torch.FloatTensor(normalized).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    return image_tensor, img\n",
    "\n",
    "def predict_image(graph, image_tensor):\n",
    "    \"\"\"\n",
    "    使用量化后的模型预测图像的类别置信度。\n",
    "    \"\"\"\n",
    "    executor = TorchExecutor(graph=graph, device='cpu')\n",
    "    with torch.no_grad():\n",
    "        outputs = executor.forward(inputs=[image_tensor])\n",
    "        confidences = torch.softmax(outputs[0], dim=1).numpy().flatten()\n",
    "    \n",
    "    return confidences\n",
    "\n",
    "# 定义手势类别\n",
    "gesture_labels = {\n",
    "    '00': 'palm',\n",
    "    '01': 'l',\n",
    "    '02': 'fist',\n",
    "    '03': 'thumb',\n",
    "    '04': 'index',\n",
    "    '05': 'ok',\n",
    "    '06': 'c',\n",
    "    '07': 'down'\n",
    "}\n",
    "\n",
    "# 加载并预处理图像\n",
    "# 请将 \"your_image.jpg\" 替换为你要预测的图像的实际路径，例如：\"/path/to/your_image.jpg\"\n",
    "image_path = \"../dataset/Web_Images_Processed_Versions/rotated_fist_image_45_degrees.png\"  # 这里将 \"your_image.jpg\" 替换为你要使用的图像路径\n",
    "image_tensor, original_image = preprocess_image(image_path)\n",
    "\n",
    "# 使用量化后的模型进行预测\n",
    "confidences = predict_image(graph, image_tensor)\n",
    "\n",
    "# 打印模型输出的各个置信度，并关联类别标签\n",
    "print(\"\\n预测结果: \\n\")\n",
    "for idx, confidence in enumerate(confidences):\n",
    "    label = gesture_labels[f'{idx:02}']\n",
    "    print(f\"类别: {label}, 置信度: {confidence:.4f}\")\n",
    "\n",
    "# 显示原始图片\n",
    "plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python esp-dl",
   "language": "python",
   "name": "esp-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
