{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164763c4-862d-40ce-82c3-d3274086e279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ___________ ____        ____  ____  ____ \n",
      "   / ____/ ___// __ \\      / __ \\/ __ \\/ __ \\\n",
      "  / __/  \\__ \\/ /_/ /_____/ /_/ / /_/ / / / /\n",
      " / /___ ___/ / ____/_____/ ____/ ____/ /_/ / \n",
      "/_____//____/_/         /_/   /_/    \\___\\_\\ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 导入必要的包\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pickle\n",
    "import numpy as np\n",
    "from ppq.api import espdl_quantize_onnx, get_target_platform\n",
    "from ppq.core import TargetPlatform\n",
    "from ppq.api.setting import QuantizationSettingFactory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1462b87b-40f6-46b9-ba08-7c7b138bd74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: 准备校准数据集\n",
    "class CalibrationDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.FloatTensor(X).unsqueeze(1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "# 加载校准数据\n",
    "with open('../dataset/cal.pkl', 'rb') as f:\n",
    "    X_cal, _ = pickle.load(f)\n",
    "\n",
    "cal_dataset = CalibrationDataset(X_cal)\n",
    "cal_loader = DataLoader(cal_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc225631-169c-4f63-9e34-f01d196d425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14:33:58] PPQ Quantization Fusion Pass Running ...       Finished.\n",
      "[14:33:58] PPQ Quantize Simplify Pass Running ...         Finished.\n",
      "[14:33:58] PPQ Parameter Quantization Pass Running ...    Finished.\n",
      "[14:33:58] PPQ Runtime Calibration Pass Running ...       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1): 100%|████████████| 50/50 [00:02<00:00, 17.02it/s]\n",
      "Calibration Progress(Phase 2): 100%|████████████| 50/50 [00:04<00:00, 10.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "[14:34:07] PPQ Quantization Alignment Pass Running ...    Finished.\n",
      "[14:34:07] PPQ Passive Parameter Quantization Running ... Finished.\n",
      "--------- Network Snapshot ---------\n",
      "Num of Op:                    [27]\n",
      "Num of Quantized Op:          [27]\n",
      "Num of Variable:              [74]\n",
      "Num of Quantized Var:         [74]\n",
      "------- Quantization Snapshot ------\n",
      "Num of Quant Config:          [102]\n",
      "ACTIVATED:                    [31]\n",
      "OVERLAPPED:                   [33]\n",
      "PASSIVE:                      [38]\n",
      "Network Quantization Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysing Graphwise Quantization Error(Phrase 1):: 100%|█| 8/8 [00:00<00:00, 13.\n",
      "Analysing Graphwise Quantization Error(Phrase 2):: 100%|█| 8/8 [00:01<00:00,  5.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                              | NOISE:SIGNAL POWER RATIO \n",
      "/layers/layers.1/conv/conv.6/Conv: | ████████████████████ | 347.308%\n",
      "/layers/layers.2/conv/conv.3/Conv: | ███████████████████  | 327.313%\n",
      "/layers/layers.2/conv/conv.0/Conv: | ███████████████████  | 326.920%\n",
      "/classifier/classifier.2/Gemm:     | ████████████████     | 287.401%\n",
      "/layers/layers.2/conv/conv.6/Conv: | ███████████████      | 269.612%\n",
      "/layers/layers.3/conv/conv.3/Conv: | ███████████████      | 268.106%\n",
      "/layers/layers.3/conv/conv.0/Conv: | ██████████████       | 246.990%\n",
      "/layers/layers.1/conv/conv.3/Conv: | ██████████████       | 242.841%\n",
      "/layers/layers.0/conv/conv.6/Conv: | █████████████        | 234.783%\n",
      "/layers/layers.1/conv/conv.0/Conv: | ████████████         | 209.285%\n",
      "/layers/layers.0/conv/conv.3/Conv: | █████████            | 166.581%\n",
      "/layers/layers.3/conv/conv.6/Conv: | ████████             | 159.707%\n",
      "/layers/layers.0/conv/conv.0/Conv: | ██                   | 61.218%\n",
      "/first/first.0/Conv:               |                      | 21.710%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysing Layerwise quantization error:: 100%|██| 14/14 [00:10<00:00,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                              | NOISE:SIGNAL POWER RATIO \n",
      "/first/first.0/Conv:               | ████████████████████ | 296.322%\n",
      "/layers/layers.1/conv/conv.3/Conv: |                      | 0.394%\n",
      "/layers/layers.3/conv/conv.3/Conv: |                      | 0.292%\n",
      "/layers/layers.0/conv/conv.3/Conv: |                      | 0.140%\n",
      "/layers/layers.2/conv/conv.0/Conv: |                      | 0.131%\n",
      "/layers/layers.2/conv/conv.3/Conv: |                      | 0.112%\n",
      "/layers/layers.0/conv/conv.0/Conv: |                      | 0.108%\n",
      "/layers/layers.3/conv/conv.0/Conv: |                      | 0.087%\n",
      "/layers/layers.0/conv/conv.6/Conv: |                      | 0.061%\n",
      "/layers/layers.1/conv/conv.6/Conv: |                      | 0.049%\n",
      "/layers/layers.2/conv/conv.6/Conv: |                      | 0.048%\n",
      "/layers/layers.1/conv/conv.0/Conv: |                      | 0.022%\n",
      "/classifier/classifier.2/Gemm:     |                      | 0.018%\n",
      "/layers/layers.3/conv/conv.6/Conv: |                      | 0.008%\n",
      "\u001b[38;5;2m[INFO][ESPDL][2024-12-16 14:34:19]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2024-12-16 14:34:19]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2024-12-16 14:34:19]:  \u001b[mskip not QuantableOperation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: 配置量化参数并执行量化\n",
    "ONNX_MODEL_PATH = \"../training/gesture_model.onnx\"\n",
    "EXPORT_PATH = \"../deployment/model/gesture_model_mixed.espdl\"\n",
    "input_shape = [1, 1, 96, 96]\n",
    "\n",
    "# 创建量化设置\n",
    "setting = QuantizationSettingFactory.espdl_setting()\n",
    "\n",
    "# 配置混合精度量化\n",
    "for layer in [\"/first/first.0/Conv\", \"/first/first.2/Clip\"]:\n",
    "    setting.dispatching_table.append(\n",
    "        layer, \n",
    "        get_target_platform(\"esp32s3\", 16)  # 使用get_target_platform替代直接指定平台\n",
    "    )\n",
    "\n",
    "# 执行量化，参数遵循interface定义\n",
    "graph = espdl_quantize_onnx(\n",
    "    onnx_import_file=ONNX_MODEL_PATH,\n",
    "    espdl_export_file=EXPORT_PATH,\n",
    "    calib_dataloader=cal_loader,\n",
    "    calib_steps=50,\n",
    "    input_shape=[input_shape],\n",
    "    target=\"esp32s3\",\n",
    "    num_of_bits=8,\n",
    "    setting=setting,\n",
    "    device=\"cpu\",\n",
    "    error_report=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0ea0a-a68c-4166-b89e-fd9a8f30f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: 评估量化后的模型\n",
    "from ppq.executor import TorchExecutor\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_quantized_model(graph, test_loader, y_test):\n",
    "    \"\"\"\n",
    "    评估量化后的模型性能\n",
    "    \"\"\"\n",
    "    executor = TorchExecutor(graph=graph, device='cpu')\n",
    "    total_time = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    print(\"\\n开始评估量化模型性能...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            start = time.time()\n",
    "            outputs = executor.forward(inputs=batch)\n",
    "            total_time += (time.time() - start)\n",
    "            \n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(outputs[0], 1)\n",
    "            total += batch.size(0)\n",
    "            correct += (predicted == y_test[total-batch.size(0):total]).sum().item()\n",
    "\n",
    "    # 计算并打印结果\n",
    "    avg_time = (total_time / len(test_loader)) * 1000  # 转换为毫秒\n",
    "    accuracy = (correct / total) * 100\n",
    "\n",
    "    print(f\"\\n评估结果:\")\n",
    "    print(f\"平均推理时间: {avg_time:.2f} ms\")\n",
    "    print(f\"模型准确率: {accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_time, accuracy\n",
    "\n",
    "# 加载测试数据\n",
    "with open('../dataset/test.pkl', 'rb') as f:\n",
    "    X_test, y_test = pickle.load(f)\n",
    "\n",
    "# 准备测试数据集\n",
    "test_dataset = CalibrationDataset(X_test)  # 复用之前的Dataset类\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 执行评估\n",
    "evaluate_quantized_model(graph, test_loader, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49fe4a-1da1-48db-b48f-ef34dd983ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d135bd3-0700-4c8b-ac2c-6549d3bf0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: 使用量化后的模型识别一张图片\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    图片预处理函数\n",
    "    1. 读取图片\n",
    "    2. 转换为灰度图\n",
    "    3. 调整大小\n",
    "    4. 归一化\n",
    "    \"\"\"\n",
    "    # 读取图片\n",
    "    img = cv2.imread(image_path)\n",
    "    # 转换为灰度图\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 调整大小\n",
    "    TARGET_SIZE = (96, 96)\n",
    "    resized = cv2.resize(gray, TARGET_SIZE)\n",
    "    # 归一化\n",
    "    normalized = resized.astype('float32') / 255.0\n",
    "    # 添加 batch 和 channel 维度\n",
    "    image_tensor = torch.FloatTensor(normalized).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    return image_tensor, img\n",
    "\n",
    "def predict_image(graph, image_tensor):\n",
    "    \"\"\"\n",
    "    使用量化后的模型预测图像的类别置信度。\n",
    "    \"\"\"\n",
    "    executor = TorchExecutor(graph=graph, device='cpu')\n",
    "    with torch.no_grad():\n",
    "        outputs = executor.forward(inputs=[image_tensor])\n",
    "        confidences = torch.softmax(outputs[0], dim=1).numpy().flatten()\n",
    "    \n",
    "    return confidences\n",
    "\n",
    "# 定义手势类别\n",
    "gesture_labels = {\n",
    "    '00': 'palm',\n",
    "    '01': 'l',\n",
    "    '02': 'fist',\n",
    "    '03': 'thumb',\n",
    "    '04': 'index',\n",
    "    '05': 'ok',\n",
    "    '06': 'c',\n",
    "    '07': 'down'\n",
    "}\n",
    "\n",
    "# 加载并预处理图像\n",
    "# 请将 \"your_image.jpg\" 替换为你要预测的图像的实际路径，例如：\"/path/to/your_image.jpg\"\n",
    "image_path = \"../dataset/Dataset_Sample_Images_ByCategory/frame_00_03_0038.png\"  # 这里将 \"your_image.jpg\" 替换为你要使用的图像路径\n",
    "image_tensor, original_image = preprocess_image(image_path)\n",
    "\n",
    "# 使用量化后的模型进行预测\n",
    "confidences = predict_image(graph, image_tensor)\n",
    "\n",
    "# 打印模型输出的各个置信度，并关联类别标签\n",
    "print(\"\\n预测结果: \\n\")\n",
    "for idx, confidence in enumerate(confidences):\n",
    "    label = gesture_labels[f'{idx:02}']\n",
    "    print(f\"类别: {label}, 置信度: {confidence:.4f}\")\n",
    "\n",
    "# 显示原始图片\n",
    "plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python esp-dl",
   "language": "python",
   "name": "esp-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
