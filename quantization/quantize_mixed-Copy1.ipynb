{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "164763c4-862d-40ce-82c3-d3274086e279",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    ___________ ____        ____  ____  ____ \n",
      "   / ____/ ___// __ \\      / __ \\/ __ \\/ __ \\\n",
      "  / __/  \\__ \\/ /_/ /_____/ /_/ / /_/ / / / /\n",
      " / /___ ___/ / ____/_____/ ____/ ____/ /_/ / \n",
      "/_____//____/_/         /_/   /_/    \\___\\_\\ \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: 导入必要的包\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import pickle\n",
    "import numpy as np\n",
    "from ppq.api import espdl_quantize_onnx, get_target_platform\n",
    "from ppq.core import TargetPlatform, QuantizationStates, QuantizationPolicy, QuantizationProperty\n",
    "from ppq.api.setting import QuantizationSettingFactory\n",
    "from ppq.parser.espdl.espdl_typedef import ExporterPatternInfo\n",
    "from ppq.IR import QuantableOperation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1462b87b-40f6-46b9-ba08-7c7b138bd74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: 准备校准数据集\n",
    "class CalibrationDataset(Dataset):\n",
    "    def __init__(self, X):\n",
    "        self.X = torch.FloatTensor(X).unsqueeze(1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx]\n",
    "\n",
    "# 加载校准数据\n",
    "with open('../dataset/cal.pkl', 'rb') as f:\n",
    "    X_cal, _ = pickle.load(f)\n",
    "\n",
    "cal_dataset = CalibrationDataset(X_cal)\n",
    "cal_loader = DataLoader(cal_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0e120eae-d3ed-4419-a483-baad9aba1d2c",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'graph' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mdir\u001b[39m(\u001b[43mgraph\u001b[49m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'graph' is not defined"
     ]
    }
   ],
   "source": [
    "print(dir(graph))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457229e-5b9b-4dbb-9e5e-7543721ff980",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pprint\n",
    "\n",
    "def pretty_print_graph(graph_dict):\n",
    "    def print_dict(d, indent=0):\n",
    "        for key, value in d.items():\n",
    "            prefix = ' ' * indent\n",
    "            if isinstance(value, dict):\n",
    "                print(f\"{prefix}{key}: {{\")\n",
    "                print_dict(value, indent + 4)\n",
    "                print(f\"{prefix}}}\")\n",
    "            else:\n",
    "                if isinstance(value, list):\n",
    "                    print(f\"{prefix}{key}: [\")\n",
    "                    for item in value:\n",
    "                        print(f\"{' ' * (indent + 4)}{item},\")\n",
    "                    print(f\"{prefix}]\")\n",
    "                else:\n",
    "                    print(f\"{prefix}{key}: {value}\")\n",
    "\n",
    "    print(\"Graph Attributes:\\n\")\n",
    "    if isinstance(graph_dict, dict):\n",
    "        print_dict(graph_dict)\n",
    "    else:\n",
    "        print(\"The provided input is not a dictionary.\")\n",
    "\n",
    "# Assuming graph.__dict__ has been assigned to the variable 'graph_dict'\n",
    "graph_dict = graph.__dict__\n",
    "\n",
    "# Use the function to print the graph attributes in a formatted way\n",
    "pretty_print_graph(graph_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc225631-169c-4f63-9e34-f01d196d425a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;3m[WARNING][ESPDL][2024-12-02 20:45:12]:  \u001b[mDo not support num_of_bits:32, will change to TargetPlatform.FP32\n",
      "[20:45:12] PPQ Quantization Fusion Pass Running ...       Finished.\n",
      "[20:45:12] PPQ Quantize Simplify Pass Running ...         Finished.\n",
      "[20:45:12] PPQ Parameter Quantization Pass Running ...    Finished.\n",
      "[20:45:12] PPQ Runtime Calibration Pass Running ...       "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Calibration Progress(Phase 1): 100%|████████████| 50/50 [00:03<00:00, 14.10it/s]\n",
      "Calibration Progress(Phase 2): 100%|████████████| 50/50 [00:04<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished.\n",
      "[20:45:21] PPQ Quantization Alignment Pass Running ...    Finished.\n",
      "[20:45:21] PPQ Passive Parameter Quantization Running ... Finished.\n",
      "--------- Network Snapshot ---------\n",
      "Num of Op:                    [27]\n",
      "Num of Quantized Op:          [26]\n",
      "Num of Variable:              [74]\n",
      "Num of Quantized Var:         [71]\n",
      "------- Quantization Snapshot ------\n",
      "Num of Quant Config:          [98]\n",
      "ACTIVATED:                    [29]\n",
      "OVERLAPPED:                   [32]\n",
      "PASSIVE:                      [37]\n",
      "Network Quantization Finished.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysing Graphwise Quantization Error(Phrase 1):: 100%|█| 8/8 [00:00<00:00,  8.\n",
      "Analysing Graphwise Quantization Error(Phrase 2):: 100%|█| 8/8 [00:01<00:00,  4.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                              | NOISE:SIGNAL POWER RATIO \n",
      "/classifier/classifier.2/Gemm:     | ████████████████████ | 15.570%\n",
      "/layers/layers.3/conv/conv.6/Conv: | ████████████████     | 12.826%\n",
      "/layers/layers.3/conv/conv.3/Conv: | ████████             | 7.020%\n",
      "/layers/layers.2/conv/conv.6/Conv: | ███████              | 6.491%\n",
      "/layers/layers.3/conv/conv.0/Conv: | ██████               | 6.142%\n",
      "/layers/layers.2/conv/conv.3/Conv: | ███                  | 4.065%\n",
      "/layers/layers.1/conv/conv.6/Conv: | ███                  | 3.711%\n",
      "/layers/layers.0/conv/conv.3/Conv: | ██                   | 3.312%\n",
      "/layers/layers.1/conv/conv.3/Conv: | ██                   | 3.204%\n",
      "/layers/layers.2/conv/conv.0/Conv: | ██                   | 3.012%\n",
      "/layers/layers.0/conv/conv.6/Conv: | █                    | 2.253%\n",
      "/layers/layers.1/conv/conv.0/Conv: | █                    | 2.236%\n",
      "/layers/layers.0/conv/conv.0/Conv: |                      | 1.632%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Analysing Layerwise quantization error:: 100%|██| 13/13 [00:13<00:00,  1.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer                              | NOISE:SIGNAL POWER RATIO \n",
      "/layers/layers.0/conv/conv.0/Conv: | ████████████████████ | 1.031%\n",
      "/layers/layers.0/conv/conv.3/Conv: | █████████████        | 0.698%\n",
      "/layers/layers.2/conv/conv.3/Conv: | ████████████         | 0.625%\n",
      "/layers/layers.3/conv/conv.3/Conv: | ████                 | 0.214%\n",
      "/layers/layers.0/conv/conv.6/Conv: | ███                  | 0.140%\n",
      "/layers/layers.1/conv/conv.0/Conv: | ██                   | 0.129%\n",
      "/layers/layers.1/conv/conv.3/Conv: | █                    | 0.084%\n",
      "/layers/layers.1/conv/conv.6/Conv: | █                    | 0.068%\n",
      "/layers/layers.2/conv/conv.6/Conv: | █                    | 0.063%\n",
      "/layers/layers.3/conv/conv.0/Conv: | █                    | 0.046%\n",
      "/classifier/classifier.2/Gemm:     | █                    | 0.042%\n",
      "/layers/layers.2/conv/conv.0/Conv: | █                    | 0.040%\n",
      "/layers/layers.3/conv/conv.6/Conv: |                      | 0.012%\n",
      "\u001b[38;5;2m[INFO][ESPDL][2024-12-02 20:45:37]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2024-12-02 20:45:37]:  \u001b[mskip not QuantableOperation\n",
      "\u001b[38;5;2m[INFO][ESPDL][2024-12-02 20:45:37]:  \u001b[mskip not QuantableOperation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 3: 配置混合精度量化参数并执行量化\n",
    "ONNX_MODEL_PATH = \"../training/gesture_model.onnx\"\n",
    "EXPORT_PATH = \"../deployment/model/gesture_model_mixed.espdl\"\n",
    "input_shape = [1, 1, 96, 96]\n",
    "\n",
    "# 设置混合精度量化配置\n",
    "setting = QuantizationSettingFactory.espdl_setting()\n",
    "\n",
    "# 对高误差层使用16位量化\n",
    "high_error_layers = [\n",
    "    \"/first/first.0/Conv\"\n",
    "]\n",
    "\n",
    "for layer in high_error_layers:\n",
    "    setting.dispatching_table.append(layer, get_target_platform(\"esp32s3\", 32))\n",
    "\n",
    "setting.policy = QuantizationPolicy(\n",
    "    QuantizationProperty.SYMMETRICAL + \n",
    "    QuantizationProperty.LINEAR +\n",
    "    QuantizationProperty.PER_TENSOR +\n",
    "    QuantizationProperty.POWER_OF_2\n",
    ")\n",
    "\n",
    "info = ExporterPatternInfo()\n",
    "graph.set_extension_attrib('espdl_pattern_info', info)\n",
    "\n",
    "for op in graph.operations.values():\n",
    "    if isinstance(op, QuantableOperation):\n",
    "        for config, var in op.config_with_variable:\n",
    "            if config.state != QuantizationStates.FP32:\n",
    "                if config.scale is not None:\n",
    "                    # 计算每个scale对应的exponent\n",
    "                    # print(config.scale)\n",
    "                    exponent = [-int(torch.floor(torch.log2(config.scale)))]\n",
    "                    info.add_var_exponents(var.name, exponent)\n",
    "                else:\n",
    "                    info.add_var_exponents(var.name, [0])\n",
    "\n",
    "# 为所有变量设置默认exponent\n",
    "for var in graph.variables.values():\n",
    "    if not info.get_var_exponents(var.name):\n",
    "        info.add_var_exponents(var.name, [0])\n",
    "\n",
    "# 执行量化\n",
    "graph = espdl_quantize_onnx(\n",
    "    onnx_import_file=ONNX_MODEL_PATH,\n",
    "    espdl_export_file=EXPORT_PATH,\n",
    "    calib_dataloader=cal_loader,\n",
    "    calib_steps=50,\n",
    "    input_shape=[input_shape],\n",
    "    target=\"esp32s3\",\n",
    "    num_of_bits=8,\n",
    "    setting=setting,\n",
    "    device=\"cpu\",\n",
    "    error_report=True,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1d0ea0a-a68c-4166-b89e-fd9a8f30f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: 评估量化后的模型\n",
    "from ppq.executor import TorchExecutor\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_quantized_model(graph, test_loader, y_test):\n",
    "    \"\"\"\n",
    "    评估量化后的模型性能\n",
    "    \"\"\"\n",
    "    executor = TorchExecutor(graph=graph, device='cpu')\n",
    "    total_time = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    print(\"\\n开始评估量化模型性能...\")\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader):\n",
    "            start = time.time()\n",
    "            outputs = executor.forward(inputs=batch)\n",
    "            total_time += (time.time() - start)\n",
    "            \n",
    "            # 计算准确率\n",
    "            _, predicted = torch.max(outputs[0], 1)\n",
    "            total += batch.size(0)\n",
    "            correct += (predicted == y_test[total-batch.size(0):total]).sum().item()\n",
    "\n",
    "    # 计算并打印结果\n",
    "    avg_time = (total_time / len(test_loader)) * 1000  # 转换为毫秒\n",
    "    accuracy = (correct / total) * 100\n",
    "\n",
    "    print(f\"\\n评估结果:\")\n",
    "    print(f\"平均推理时间: {avg_time:.2f} ms\")\n",
    "    print(f\"模型准确率: {accuracy:.2f}%\")\n",
    "    \n",
    "    return avg_time, accuracy\n",
    "\n",
    "# 加载测试数据\n",
    "with open('../dataset/test.pkl', 'rb') as f:\n",
    "    X_test, y_test = pickle.load(f)\n",
    "\n",
    "# 准备测试数据集\n",
    "test_dataset = CalibrationDataset(X_test)  # 复用之前的Dataset类\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# 执行评估\n",
    "evaluate_quantized_model(graph, test_loader, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "869ae916-f6d4-4d1e-bbc3-e622dd8a4526",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Operation: /first/first.0/Conv\n",
      "Input 'input' shape: [1, 1, 96, 96]\n",
      "Input 'onnx::Conv_140' shape: [16, 1, 3, 3]\n",
      "Input 'onnx::Conv_141' shape: [16]\n",
      "Output '/first/first.0/Conv_output_0' shape: [1, 16, 48, 48]\n",
      "\n",
      "Operation: /first/first.2/Clip\n",
      "Input '/first/first.0/Conv_output_0' shape: [1, 16, 48, 48]\n",
      "Input '/first/first.2/Constant_output_0' shape: []\n",
      "Input '/first/first.2/Constant_1_output_0' shape: []\n",
      "Output '/first/first.2/Clip_output_0' shape: [1, 16, 48, 48]\n",
      "\n",
      "Operation: /layers/layers.0/conv/conv.0/Conv\n",
      "Input '/first/first.2/Clip_output_0' shape: [1, 16, 48, 48]\n",
      "Input 'onnx::Conv_143' shape: [96, 16, 1, 1]\n",
      "Input 'onnx::Conv_144' shape: [96]\n",
      "Output '/layers/layers.0/conv/conv.0/Conv_output_0' shape: [1, 96, 48, 48]\n",
      "\n",
      "Operation: /layers/layers.0/conv/conv.2/Clip\n",
      "Input '/layers/layers.0/conv/conv.0/Conv_output_0' shape: [1, 96, 48, 48]\n",
      "Input '/layers/layers.0/conv/conv.2/Constant_output_0' shape: []\n",
      "Input '/layers/layers.0/conv/conv.2/Constant_1_output_0' shape: []\n",
      "Output '/layers/layers.0/conv/conv.2/Clip_output_0' shape: [1, 96, 48, 48]\n",
      "\n",
      "Operation: /layers/layers.0/conv/conv.3/Conv\n",
      "Input '/layers/layers.0/conv/conv.2/Clip_output_0' shape: [1, 96, 48, 48]\n",
      "Input 'onnx::Conv_146' shape: [96, 1, 3, 3]\n",
      "Input 'onnx::Conv_147' shape: [96]\n",
      "Output '/layers/layers.0/conv/conv.3/Conv_output_0' shape: [1, 96, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.0/conv/conv.5/Clip\n",
      "Input '/layers/layers.0/conv/conv.3/Conv_output_0' shape: [1, 96, 24, 24]\n",
      "Input '/layers/layers.0/conv/conv.5/Constant_output_0' shape: []\n",
      "Input '/layers/layers.0/conv/conv.5/Constant_1_output_0' shape: []\n",
      "Output '/layers/layers.0/conv/conv.5/Clip_output_0' shape: [1, 96, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.0/conv/conv.6/Conv\n",
      "Input '/layers/layers.0/conv/conv.5/Clip_output_0' shape: [1, 96, 24, 24]\n",
      "Input 'onnx::Conv_149' shape: [24, 96, 1, 1]\n",
      "Input 'onnx::Conv_150' shape: [24]\n",
      "Output '/layers/layers.0/conv/conv.6/Conv_output_0' shape: [1, 24, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.1/conv/conv.0/Conv\n",
      "Input '/layers/layers.0/conv/conv.6/Conv_output_0' shape: [1, 24, 24, 24]\n",
      "Input 'onnx::Conv_152' shape: [144, 24, 1, 1]\n",
      "Input 'onnx::Conv_153' shape: [144]\n",
      "Output '/layers/layers.1/conv/conv.0/Conv_output_0' shape: [1, 144, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.1/conv/conv.2/Clip\n",
      "Input '/layers/layers.1/conv/conv.0/Conv_output_0' shape: [1, 144, 24, 24]\n",
      "Input '/layers/layers.1/conv/conv.2/Constant_output_0' shape: []\n",
      "Input '/layers/layers.1/conv/conv.2/Constant_1_output_0' shape: []\n",
      "Output '/layers/layers.1/conv/conv.2/Clip_output_0' shape: [1, 144, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.1/conv/conv.3/Conv\n",
      "Input '/layers/layers.1/conv/conv.2/Clip_output_0' shape: [1, 144, 24, 24]\n",
      "Input 'onnx::Conv_155' shape: [144, 1, 3, 3]\n",
      "Input 'onnx::Conv_156' shape: [144]\n",
      "Output '/layers/layers.1/conv/conv.3/Conv_output_0' shape: [1, 144, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.1/conv/conv.5/Clip\n",
      "Input '/layers/layers.1/conv/conv.3/Conv_output_0' shape: [1, 144, 24, 24]\n",
      "Input '/layers/layers.1/conv/conv.5/Constant_output_0' shape: []\n",
      "Input '/layers/layers.1/conv/conv.5/Constant_1_output_0' shape: []\n",
      "Output '/layers/layers.1/conv/conv.5/Clip_output_0' shape: [1, 144, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.1/conv/conv.6/Conv\n",
      "Input '/layers/layers.1/conv/conv.5/Clip_output_0' shape: [1, 144, 24, 24]\n",
      "Input 'onnx::Conv_158' shape: [24, 144, 1, 1]\n",
      "Input 'onnx::Conv_159' shape: [24]\n",
      "Output '/layers/layers.1/conv/conv.6/Conv_output_0' shape: [1, 24, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.1/Add\n",
      "Input '/layers/layers.0/conv/conv.6/Conv_output_0' shape: [1, 24, 24, 24]\n",
      "Input '/layers/layers.1/conv/conv.6/Conv_output_0' shape: [1, 24, 24, 24]\n",
      "Output '/layers/layers.1/Add_output_0' shape: [1, 24, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.2/conv/conv.0/Conv\n",
      "Input '/layers/layers.1/Add_output_0' shape: [1, 24, 24, 24]\n",
      "Input 'onnx::Conv_161' shape: [144, 24, 1, 1]\n",
      "Input 'onnx::Conv_162' shape: [144]\n",
      "Output '/layers/layers.2/conv/conv.0/Conv_output_0' shape: [1, 144, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.2/conv/conv.2/Clip\n",
      "Input '/layers/layers.2/conv/conv.0/Conv_output_0' shape: [1, 144, 24, 24]\n",
      "Input '/layers/layers.2/conv/conv.2/Constant_output_0' shape: []\n",
      "Input '/layers/layers.2/conv/conv.2/Constant_1_output_0' shape: []\n",
      "Output '/layers/layers.2/conv/conv.2/Clip_output_0' shape: [1, 144, 24, 24]\n",
      "\n",
      "Operation: /layers/layers.2/conv/conv.3/Conv\n",
      "Input '/layers/layers.2/conv/conv.2/Clip_output_0' shape: [1, 144, 24, 24]\n",
      "Input 'onnx::Conv_164' shape: [144, 1, 3, 3]\n",
      "Input 'onnx::Conv_165' shape: [144]\n",
      "Output '/layers/layers.2/conv/conv.3/Conv_output_0' shape: [1, 144, 12, 12]\n",
      "\n",
      "Operation: /layers/layers.2/conv/conv.5/Clip\n",
      "Input '/layers/layers.2/conv/conv.3/Conv_output_0' shape: [1, 144, 12, 12]\n",
      "Input '/layers/layers.2/conv/conv.5/Constant_output_0' shape: []\n",
      "Input '/layers/layers.2/conv/conv.5/Constant_1_output_0' shape: []\n",
      "Output '/layers/layers.2/conv/conv.5/Clip_output_0' shape: [1, 144, 12, 12]\n",
      "\n",
      "Operation: /layers/layers.2/conv/conv.6/Conv\n",
      "Input '/layers/layers.2/conv/conv.5/Clip_output_0' shape: [1, 144, 12, 12]\n",
      "Input 'onnx::Conv_167' shape: [32, 144, 1, 1]\n",
      "Input 'onnx::Conv_168' shape: [32]\n",
      "Output '/layers/layers.2/conv/conv.6/Conv_output_0' shape: [1, 32, 12, 12]\n",
      "\n",
      "Operation: /layers/layers.3/conv/conv.0/Conv\n",
      "Input '/layers/layers.2/conv/conv.6/Conv_output_0' shape: [1, 32, 12, 12]\n",
      "Input 'onnx::Conv_170' shape: [192, 32, 1, 1]\n",
      "Input 'onnx::Conv_171' shape: [192]\n",
      "Output '/layers/layers.3/conv/conv.0/Conv_output_0' shape: [1, 192, 12, 12]\n",
      "\n",
      "Operation: /layers/layers.3/conv/conv.2/Clip\n",
      "Input '/layers/layers.3/conv/conv.0/Conv_output_0' shape: [1, 192, 12, 12]\n",
      "Input '/layers/layers.3/conv/conv.2/Constant_output_0' shape: []\n",
      "Input '/layers/layers.3/conv/conv.2/Constant_1_output_0' shape: []\n",
      "Output '/layers/layers.3/conv/conv.2/Clip_output_0' shape: [1, 192, 12, 12]\n",
      "\n",
      "Operation: /layers/layers.3/conv/conv.3/Conv\n",
      "Input '/layers/layers.3/conv/conv.2/Clip_output_0' shape: [1, 192, 12, 12]\n",
      "Input 'onnx::Conv_173' shape: [192, 1, 3, 3]\n",
      "Input 'onnx::Conv_174' shape: [192]\n",
      "Output '/layers/layers.3/conv/conv.3/Conv_output_0' shape: [1, 192, 12, 12]\n",
      "\n",
      "Operation: /layers/layers.3/conv/conv.5/Clip\n",
      "Input '/layers/layers.3/conv/conv.3/Conv_output_0' shape: [1, 192, 12, 12]\n",
      "Input '/layers/layers.3/conv/conv.5/Constant_output_0' shape: []\n",
      "Input '/layers/layers.3/conv/conv.5/Constant_1_output_0' shape: []\n",
      "Output '/layers/layers.3/conv/conv.5/Clip_output_0' shape: [1, 192, 12, 12]\n",
      "\n",
      "Operation: /layers/layers.3/conv/conv.6/Conv\n",
      "Input '/layers/layers.3/conv/conv.5/Clip_output_0' shape: [1, 192, 12, 12]\n",
      "Input 'onnx::Conv_176' shape: [32, 192, 1, 1]\n",
      "Input 'onnx::Conv_177' shape: [32]\n",
      "Output '/layers/layers.3/conv/conv.6/Conv_output_0' shape: [1, 32, 12, 12]\n",
      "\n",
      "Operation: /layers/layers.3/Add\n",
      "Input '/layers/layers.2/conv/conv.6/Conv_output_0' shape: [1, 32, 12, 12]\n",
      "Input '/layers/layers.3/conv/conv.6/Conv_output_0' shape: [1, 32, 12, 12]\n",
      "Output '/layers/layers.3/Add_output_0' shape: [1, 32, 12, 12]\n",
      "\n",
      "Operation: /classifier/classifier.0/GlobalAveragePool\n",
      "Input '/layers/layers.3/Add_output_0' shape: [1, 32, 12, 12]\n",
      "Output '/classifier/classifier.0/GlobalAveragePool_output_0' shape: [1, 32, 1, 1]\n",
      "\n",
      "Operation: /classifier/classifier.1/Flatten\n",
      "Input '/classifier/classifier.0/GlobalAveragePool_output_0' shape: [1, 32, 1, 1]\n",
      "Output '/classifier/classifier.1/Flatten_output_0' shape: [1, 32]\n",
      "\n",
      "Operation: /classifier/classifier.2/Gemm\n",
      "Input '/classifier/classifier.1/Flatten_output_0' shape: [1, 32]\n",
      "Input 'classifier.2.weight' shape: [8, 32]\n",
      "Input 'classifier.2.bias' shape: [8]\n",
      "Output 'output' shape: [1, 8]\n"
     ]
    }
   ],
   "source": [
    "# 遍历图中的所有操作\n",
    "for op in graph.operations.values():\n",
    "    print(f\"\\nOperation: {op.name}\")\n",
    "    # 打印输入形状\n",
    "    for inp in op.inputs:\n",
    "        print(f\"Input '{inp.name}' shape: {inp.shape}\")\n",
    "    # 打印输出形状  \n",
    "    for out in op.outputs:\n",
    "        print(f\"Output '{out.name}' shape: {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b9e359d-1b05-4a56-8583-754dfb5f71c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看第一层量化配置\n",
    "first_conv = graph.operations['/first/first.0/Conv']\n",
    "if isinstance(first_conv, QuantableOperation):\n",
    "   for config, var in first_conv.config_with_variable:\n",
    "       print(f\"\\nVariable: {var.name}\")\n",
    "       print(f\"State: {config.state}\")\n",
    "       print(f\"Platform: {config.platform}\")\n",
    "       print(f\"Bit width: {config.num_of_bits}\")\n",
    "       print(f\"Scale: {config.scale}\")\n",
    "       print(f\"Offset: {config.offset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c49fe4a-1da1-48db-b48f-ef34dd983ecf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls *.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d135bd3-0700-4c8b-ac2c-6549d3bf0228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: 使用量化后的模型识别一张图片\n",
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    \"\"\"\n",
    "    图片预处理函数\n",
    "    1. 读取图片\n",
    "    2. 转换为灰度图\n",
    "    3. 调整大小\n",
    "    4. 归一化\n",
    "    \"\"\"\n",
    "    # 读取图片\n",
    "    img = cv2.imread(image_path)\n",
    "    # 转换为灰度图\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # 调整大小\n",
    "    TARGET_SIZE = (96, 96)\n",
    "    resized = cv2.resize(gray, TARGET_SIZE)\n",
    "    # 归一化\n",
    "    normalized = resized.astype('float32') / 255.0\n",
    "    # 添加 batch 和 channel 维度\n",
    "    image_tensor = torch.FloatTensor(normalized).unsqueeze(0).unsqueeze(0)\n",
    "    \n",
    "    return image_tensor, img\n",
    "\n",
    "def predict_image(graph, image_tensor):\n",
    "    \"\"\"\n",
    "    使用量化后的模型预测图像的类别置信度。\n",
    "    \"\"\"\n",
    "    executor = TorchExecutor(graph=graph, device='cpu')\n",
    "    with torch.no_grad():\n",
    "        outputs = executor.forward(inputs=[image_tensor])\n",
    "        confidences = torch.softmax(outputs[0], dim=1).numpy().flatten()\n",
    "    \n",
    "    return confidences\n",
    "\n",
    "# 定义手势类别\n",
    "gesture_labels = {\n",
    "    '00': 'palm',\n",
    "    '01': 'l',\n",
    "    '02': 'fist',\n",
    "    '03': 'thumb',\n",
    "    '04': 'index',\n",
    "    '05': 'ok',\n",
    "    '06': 'c',\n",
    "    '07': 'down'\n",
    "}\n",
    "\n",
    "# 加载并预处理图像\n",
    "# 请将 \"your_image.jpg\" 替换为你要预测的图像的实际路径，例如：\"/path/to/your_image.jpg\"\n",
    "image_path = \"frame_00_01_0009.png\"  # 这里将 \"your_image.jpg\" 替换为你要使用的图像路径\n",
    "image_tensor, original_image = preprocess_image(image_path)\n",
    "\n",
    "# 使用量化后的模型进行预测\n",
    "confidences = predict_image(graph, image_tensor)\n",
    "\n",
    "# 打印模型输出的各个置信度，并关联类别标签\n",
    "print(\"\\n预测结果: \\n\")\n",
    "for idx, confidence in enumerate(confidences):\n",
    "    label = gesture_labels[f'{idx:02}']\n",
    "    print(f\"类别: {label}, 置信度: {confidence:.4f}\")\n",
    "\n",
    "# 显示原始图片\n",
    "plt.imshow(cv2.cvtColor(original_image, cv2.COLOR_BGR2RGB))\n",
    "plt.title(\"Original Image\")\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python esp-dl",
   "language": "python",
   "name": "esp-dl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
