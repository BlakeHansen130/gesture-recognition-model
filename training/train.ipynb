{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2910d1-56df-461d-ae80-484cb7c22397",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec213b9-5f9c-4b09-a626-02ef45baf052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import import_ipynb\n",
    "import model  # 这里的 model 是你定义模型的那个 .ipynb 文件的名称（去掉 .ipynb 后缀）\n",
    "from model import LightGestureNet\n",
    "from model import InvertedResidual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91326e4b-9282-4fe1-b88f-8488ddfeac5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GestureDataset(Dataset):\n",
    "    def __init__(self, X, y, transform=None):\n",
    "        # 确保数据格式正确\n",
    "        self.X = torch.FloatTensor(X).unsqueeze(1)  # 添加通道维度\n",
    "        self.y = torch.LongTensor(y)\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.X[idx]\n",
    "        label = self.y[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label\n",
    "        \n",
    "# 添加更多正则化\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomRotation(30),  # 增大旋转角度\n",
    "    transforms.RandomAffine(0, scale=(0.8, 1.2)),  # 增大缩放范围\n",
    "    transforms.RandomAffine(0, translate=(0.2, 0.2)),  # 增大平移范围\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95293c3b-e4f0-446b-8e43-7cbd61a05160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载数据\n",
    "with open('train.pkl', 'rb') as f:\n",
    "    X_train, y_train = pickle.load(f)\n",
    "with open('test.pkl', 'rb') as f:\n",
    "    X_val, y_val = pickle.load(f)\n",
    "\n",
    "# 创建数据集实例\n",
    "train_dataset = GestureDataset(X_train, y_train, transform=train_transform)\n",
    "val_dataset = GestureDataset(X_val, y_val)\n",
    "\n",
    "# 创建数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32)\n",
    "\n",
    "print(\"训练集大小:\", len(train_dataset))\n",
    "print(\"验证集大小:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27aab9f8-243b-431a-ae6f-6f86663525ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "# 自定义权重初始化函数\n",
    "def weight_init(m):\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        # 使用 He (Kaiming) 初始化卷积层的权重\n",
    "        init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        # 使用常量初始化批归一化层\n",
    "        init.constant_(m.weight, 1)\n",
    "        init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Linear):\n",
    "        # 使用 Xavier 初始化全连接层的权重\n",
    "        init.xavier_normal_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44258f8e-582e-4922-9432-7310e7f2df73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 检查CUDA可用性并设置设备\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"使用设备: {device}\")\n",
    "\n",
    "# 加载模型并移至设备\n",
    "model = LightGestureNet().to(device)\n",
    "\n",
    "# 设置训练参数\n",
    "num_epochs = 50\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "model.apply(weight_init)  # 添加权重初始化\n",
    "scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
    "\n",
    "# 用于早停的变量\n",
    "best_val_loss = float('inf')\n",
    "patience = 5\n",
    "patience_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f8742cd-95db-48eb-b813-9725e91bb027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 记录训练历史\n",
    "history = {\n",
    "    'train_loss': [], 'train_acc': [],\n",
    "    'val_loss': [], 'val_acc': []\n",
    "}\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    # 训练模式\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    train_correct = 0\n",
    "    train_total = 0\n",
    "    \n",
    "    # 训练循环\n",
    "    for images, labels in tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        train_total += labels.size(0)\n",
    "        train_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # 计算训练指标\n",
    "    epoch_train_loss = train_loss / len(train_loader)\n",
    "    epoch_train_acc = 100. * train_correct / train_total\n",
    "    \n",
    "    # 验证模式\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_correct = 0\n",
    "    val_total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in val_loader:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            val_total += labels.size(0)\n",
    "            val_correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # 计算验证指标\n",
    "    epoch_val_loss = val_loss / len(val_loader)\n",
    "    epoch_val_acc = 100. * val_correct / val_total\n",
    "    \n",
    "    # 更新学习率\n",
    "    scheduler.step()\n",
    "    \n",
    "    # 记录历史\n",
    "    history['train_loss'].append(epoch_train_loss)\n",
    "    history['train_acc'].append(epoch_train_acc)\n",
    "    history['val_loss'].append(epoch_val_loss)\n",
    "    history['val_acc'].append(epoch_val_acc)\n",
    "    \n",
    "    print(f'\\nEpoch {epoch+1}/{num_epochs}:')\n",
    "    print(f'Train Loss: {epoch_train_loss:.4f}, Train Acc: {epoch_train_acc:.2f}%')\n",
    "    print(f'Val Loss: {epoch_val_loss:.4f}, Val Acc: {epoch_val_acc:.2f}%')\n",
    "\n",
    "    # 在训练循环开始前定义阈值\n",
    "    ACCURACY_THRESHOLD = 99.27\n",
    "\n",
    "    # 在每个epoch结束后的部分增加判断\n",
    "    if epoch_train_acc >= ACCURACY_THRESHOLD and epoch_val_acc >= ACCURACY_THRESHOLD:\n",
    "        print(f'\\n达到目标准确率! 训练终止于epoch {epoch+1}')\n",
    "        break\n",
    "    \n",
    "    # 早停检查\n",
    "    if epoch_val_loss < best_val_loss:\n",
    "        best_val_loss = epoch_val_loss\n",
    "        patience_counter = 0\n",
    "        # 保存最佳模型\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "        if patience_counter >= patience:\n",
    "            print(f'\\n早停: 验证损失在 {patience} 个epoch内没有改善')\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d366c7d-fbb1-4d65-b475-cec3db0ee185",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# 绘制损失\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_loss'], label='Training Loss')\n",
    "plt.plot(history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "# 绘制准确率\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['train_acc'], label='Training Accuracy')\n",
    "plt.plot(history['val_acc'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy (%)')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668baf27-0cdd-4e0b-bcb4-ffcdc0e9151e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import onnx\n",
    "import onnxruntime as ort\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "# 强制使用 CPU\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# 加载最佳模型并放置到 CPU 上\n",
    "model.load_state_dict(torch.load('best_model.pth', map_location=device, weights_only=False))\n",
    "model.eval()\n",
    "model.to(device)\n",
    "\n",
    "# 保存为PyTorch格式\n",
    "torch.save(model.state_dict(), 'gesture_model.pth')\n",
    "\n",
    "# 导出为ONNX格式\n",
    "dummy_input = torch.randn(1, 1, 96, 96).to(device)  # 确保输入张量在 CPU 上\n",
    "onnx_model_path = 'gesture_model.onnx'\n",
    "torch.onnx.export(model, dummy_input, onnx_model_path,\n",
    "                  input_names=['input'],\n",
    "                  output_names=['output'],\n",
    "                  dynamic_axes={'input': {0: 'batch_size'},\n",
    "                                'output': {0: 'batch_size'}})\n",
    "\n",
    "# 使用 ONNX Runtime 进行推理验证 ONNX 模型的正确性\n",
    "try:\n",
    "    ort_session = ort.InferenceSession(onnx_model_path)\n",
    "    outputs = ort_session.run(None, {'input': dummy_input.numpy()})\n",
    "    print(\"ONNX 模型推理测试成功，结果：\", outputs)\n",
    "except Exception as e:\n",
    "    print(\"Error during ONNX model inference:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# 手动构建等价的 TensorFlow 模型以便转换为 SavedModel\n",
    "class SimpleKerasModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(SimpleKerasModel, self).__init__()\n",
    "        self.conv1 = tf.keras.layers.Conv2D(16, (3, 3), padding='same', activation='relu')\n",
    "        self.pool1 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.conv2 = tf.keras.layers.Conv2D(32, (3, 3), padding='same', activation='relu')\n",
    "        self.pool2 = tf.keras.layers.MaxPooling2D((2, 2))\n",
    "        self.flatten = tf.keras.layers.Flatten()\n",
    "        self.fc1 = tf.keras.layers.Dense(128, activation='relu')\n",
    "        self.fc2 = tf.keras.layers.Dense(10)  # 假设有 10 个类\n",
    "\n",
    "    def call(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        return self.fc2(x)\n",
    "\n",
    "# 创建 TensorFlow 模型并保存为 SavedModel 格式\n",
    "try:\n",
    "    tf_model = SimpleKerasModel()\n",
    "    tf_input = tf.convert_to_tensor(np.random.randn(1, 96, 96, 1), dtype=tf.float32)\n",
    "    tf_model(tf_input)  # 通过调用一次模型来构建计算图\n",
    "    tf.saved_model.save(tf_model, 'tf_gesture_model')\n",
    "    print(f\"SavedModel 已成功生成：tf_gesture_model\")\n",
    "except Exception as e:\n",
    "    print(\"Error during manual TensorFlow model creation:\", e)\n",
    "    exit(1)\n",
    "\n",
    "# 创建 TFLite 转换器\n",
    "try:\n",
    "    converter = tf.lite.TFLiteConverter.from_saved_model('tf_gesture_model')\n",
    "\n",
    "    # 设置优化选项\n",
    "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "    converter.target_spec.supported_types = [tf.float32]\n",
    "\n",
    "    # 执行转换\n",
    "    tflite_model = converter.convert()\n",
    "\n",
    "    # 保存 TFLite 模型\n",
    "    with open('gesture_model.tflite', 'wb') as f:\n",
    "        f.write(tflite_model)\n",
    "\n",
    "    print(\"模型已保存为以下格式：\")\n",
    "    print(\"- PyTorch (.pth)\")\n",
    "    print(\"- ONNX (.onnx)\")\n",
    "    print(\"- TFLite (.tflite)\")\n",
    "except Exception as e:\n",
    "    print(\"Error during SavedModel to TFLite conversion:\", e)\n",
    "    exit(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python dl_env",
   "language": "python",
   "name": "dl_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
